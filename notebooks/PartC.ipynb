{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c32be2",
   "metadata": {},
   "source": [
    "# PART C (Neural Netwroks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066318a7",
   "metadata": {},
   "source": [
    "**import:**\n",
    "* Layer class\n",
    "* Neural Networks class\n",
    "* load_datasets() util method\n",
    "\n",
    "*Exploding gradients were observed when tried to train the model with inappropriate hyperparameters, such as big learning rate and units for hidden layer. In order to avoid runtime warnings that are destined to happen and continue training with other hyperparameters, without interrupting the code, we ignore warnings so that we can find the appropriate  hyperparameters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0215b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.NeuralNetworks import *\n",
    "from ipynb.fs.full.LoadDatasets import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2addfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_dev, y_dev, X_test, y_test = load_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a481d8a3",
   "metadata": {},
   "source": [
    "**The basic model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb68fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, y, M=16, learning_rate=0.5, epochs=100, early_stopping=True, B=128, X_dev=None, y_dev=None, use_tqdm=True):\n",
    "    hidden_layer = Layer(M, X.shape[1], activation='relu')\n",
    "    output_layer = Layer(1, M, activation='sigmoid')\n",
    "    \n",
    "    nn = NeuralNetwork()\n",
    "    nn.input_layer(X, y.reshape(-1))\n",
    "    \n",
    "    nn.add_layer(hidden_layer)\n",
    "    nn.add_layer(output_layer)\n",
    "    \n",
    "    nn.fit(learning_rate=learning_rate, epochs=epochs, early_stopping=early_stopping, X_dev=X_dev, y_dev=y_dev, B=B, use_tqdm=use_tqdm)\n",
    "    \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d36b0374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████▊                                                           | 27/100 [00:00<00:01, 55.06it/s]\n"
     ]
    }
   ],
   "source": [
    "nn1 = model(X_train, y_train, early_stopping=True, B=X_train.shape[0], X_dev=X_dev, y_dev=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4832e1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9778\n",
      "Epochs:  28\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: \", f'{nn1.accuracy(X_test, y_test.reshape(-1)):.4f}')\n",
    "print(\"Epochs: \", nn1.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e73931",
   "metadata": {},
   "source": [
    "**Initializes**\n",
    "* **the learning rates randomly** \n",
    "As we want alphas between the range [$10^{-5}$, $0.5$] :\n",
    "$10^{-5*random}$ should be less or equal than 0.5 and we end up that random >= $\\frac{log(2)}{5*log(10)}$\n",
    "\n",
    "\n",
    "* **the M array (the number of units of hidden layer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21adf7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "random.seed(42)\n",
    "start = np.log(2)/(5*np.log(10))\n",
    "alphas = np.array([10**(-5*random.uniform(start,1)) for i in range(10)])\n",
    "M = [2**i for i in range(1, 10 + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc79113f",
   "metadata": {},
   "source": [
    "**Function that tunes the hyperparameters and returns the best:**\n",
    "* **best_alpha** = Learning rate\n",
    "* **best_M** = Number of units for the hidden layer\n",
    "* **best_epochs** = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bfe14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(X_train, y_train, M, alphas, max_epochs=100, early_stopping=False, X_dev=None, y_dev=None, use_tqdm=True, B=128):\n",
    "    min_cost = 10**10\n",
    "    best_alpha = 0\n",
    "    best_M = 0\n",
    "    best_epochs = 0\n",
    "\n",
    "    for m in tqdm(M):\n",
    "        for alpha in alphas:\n",
    "            nn = model(X_train, y_train, M=m, learning_rate=alpha, epochs = max_epochs,\n",
    "                       early_stopping=early_stopping, X_dev=X_dev, y_dev=y_dev, use_tqdm=False, B=B)\n",
    "            \n",
    "            current_best_cost_index = np.argmin(nn.J)\n",
    "            if nn.J[current_best_cost_index] < min_cost:\n",
    "                min_cost=nn.J[current_best_cost_index]\n",
    "                best_alpha=alpha\n",
    "                best_M=m\n",
    "                best_epochs=current_best_cost_index + 1\n",
    "                \n",
    "            del nn\n",
    "            gc.collect()\n",
    "    \n",
    "    nn = model(X_train, y_train, M=best_M, learning_rate=best_alpha, epochs = best_epochs,\n",
    "                   early_stopping=False, X_dev=X_dev, y_dev=y_dev, use_tqdm=False, B=B)\n",
    "    \n",
    "    return nn, best_alpha, best_M, best_epochs, min_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ed4c4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [11:53<00:00, 71.38s/it]\n"
     ]
    }
   ],
   "source": [
    "nn2, best_alpha, best_M, best_epochs, min_cost = tune_model(X_train, y_train, M=M, alphas=alphas, early_stopping=True, X_dev=X_dev, y_dev=y_dev, B=X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9b02fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9780\n",
      "Best alpha:  0.19519\n",
      "Best M:  16\n",
      "best_epochs:  100\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: \", f'{nn2.accuracy(X_dev, y_dev.reshape(-1)):.4f}')\n",
    "print(\"Best alpha: \", f'{best_alpha:.5f}')\n",
    "print(\"Best M: \", best_M)\n",
    "print(\"best_epochs: \", best_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab767a81",
   "metadata": {},
   "source": [
    "**Initialize the batch sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d7a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([2**i for i in range(1, 8 + 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc569df",
   "metadata": {},
   "source": [
    "**Find best mini_batch size using the basic model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e66c3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:04<00:00,  1.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 38.59it/s]\n"
     ]
    }
   ],
   "source": [
    "min_cost = 10**10\n",
    "best_B = X_train.shape[0]\n",
    "best_B_epochs=100\n",
    "\n",
    "for batch_size in tqdm(B):\n",
    "    nn = model(X_train, y_train, early_stopping=True, B=batch_size, X_dev=X_dev, y_dev=y_dev, use_tqdm=False)\n",
    "\n",
    "    current_best_cost_index = np.argmin(nn.J)\n",
    "    if nn.J[current_best_cost_index] < min_cost:\n",
    "        min_cost=nn.J[current_best_cost_index]\n",
    "        best_B=batch_size\n",
    "        best_B_epochs=current_best_cost_index + 1\n",
    "\n",
    "nn3 = model(X_train, y_train, epochs=best_B_epochs, early_stopping=False, B=best_B, X_dev=X_dev, y_dev=y_dev, use_tqdm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f3cce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9654\n",
      "Mini batch size:  64\n",
      "Epochs:  14\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: \", f'{nn3.accuracy(X_test, y_test.reshape(-1)):.4f}')\n",
    "print(\"Mini batch size: \", best_B)\n",
    "print(\"Epochs: \", nn3.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277b8f95",
   "metadata": {},
   "source": [
    "**Find best mini_batch size, the best learning rate, best epochs and M(neurons of hidden layer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58e72a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_B_cost = 10**10\n",
    "best_B = X_train.shape[0]\n",
    "best_B_epochs=100\n",
    "best_B_alpha=0\n",
    "best_B_M = X_train.shape[0]\n",
    "\n",
    "for batch_size in B:\n",
    "    nn, best_alpha, best_M, best_epochs, min_cost = tune_model(X_train, y_train, M=M, alphas=alphas, early_stopping=True, X_dev=X_dev, \n",
    "                                                      y_dev=y_dev, B=batch_size, use_tqdm=False)\n",
    "\n",
    "    if min_cost < min_B_cost:\n",
    "        best_B=batch_size\n",
    "        best_B_epochs=best_epochs\n",
    "        best_B_alpha=best_alpha\n",
    "        best_B_M=best_M\n",
    "\n",
    "nn4 = model(X_train, y_train, M=best_M, learning_rate=best_alpha, epochs=best_B_epochs,\n",
    "                   early_stopping=False, X_dev=X_dev, y_dev=y_dev, use_tqdm=True, B=best_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0389889",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy: \", f'{nn4.accuracy(X_test, y_test.reshape(-1)):.4f}')\n",
    "print(\"Learning rate: \", f'{best_alpha:.5f}')\n",
    "print(\"Mini batch size: \", best_B)\n",
    "print(\"Number of units: \", best_B)\n",
    "print(\"Epochs: \", best_B_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
